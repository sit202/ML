import pandas as pd 
import numpy as np 
import seaborn as sns
import matplotlib.pyplot as plt
import warnings warnings.filterwarnings("ignore")
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics


data.isnull().sum()
# do this same for below all column
fig = sns.distplot(df['GRE Score'], kde=False)
plt.title("Distribution of GRE Scores")
plt.show()


# do this compare for all
fig = sns.regplot(x="GRE Score", y="CGPA", data=df)
plt.title("GRE Score vs CGPA")
plt.show()

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

models = [['DecisionTree :',DecisionTreeRegressor()],
['Linear Regression :', LinearRegression()], ['SVM :', SVR()]]
print("Results...")

For name,model in models:model = model

model.fit(X_train, y_train)

predictions = model.predict(X_test)

print(name, (np.sqrt(mean_squared_error(y_test, predictions)))) classifier = RandomForestRegressor()
classifier.fit(X,y)

feature_names = X.columns print(feature_names)
importance_frame = pd.DataFrame()
importance_frame['Features'] = X.columns
importance_frame['Importance'] = classifier.feature_importances_
importance_frame = importance_frame.sort_values(by=['Importance'], ascending=True)


plt.barh([1,2,3,4,5,6,7],
importance_frame['Importance'],
align='center', alpha=0.5)

plt.yticks([1,2,3,4,5,6,7],
importance_frame['Features'])
plt.xlabel('Importance')

plt.title('Feature Importances')
plt.show()


